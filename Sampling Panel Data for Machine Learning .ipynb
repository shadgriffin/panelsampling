{"cells": [{"metadata": {}, "cell_type": "markdown", "source": "# Assigning Panel Data to Training, Testing and Validation Groups for Machine Learning Models."}, {"metadata": {}, "cell_type": "markdown", "source": "Cross-Sectional data includes individual entities measured in one time period.   For example, if you have 10,000 people measured once, you have cross-sectional data.\n\nTime series includes one entity measured over multiple time periods.  For example, if you have a single machine measured every day for ten years, you have a time-series.\n\nPanel data includes multiple entities measured over multiple time periods.  For example, if you have 1,000 consumers measured over ten years, you have panel data. Or, if you have 100 machines measured over 100 months, you have panel data.\n\nPanel data is quite common in data science. Sometimes, it is called cross-sectional time-series data. I have also heard it referred to as pooled time series data. Whatever you want to call it, as a practicing data scientist, you'll more than likely have to deal with it.\n\nIt is standard procedure when building machine learning models that you assign your data to modeling groups. Typically, we randomly sub-set the data into Training, Testing and Validation groups. Random, in this case, means that each record in the data set has an equal chance of being assigned to one of the three groups.\n\nWhen you are working with Panel Data, however, you will need to alter the normal process a little.\n\nIn this notebook, I walk through a simple example on how to do this.\n\n\n"}, {"metadata": {}, "cell_type": "markdown", "source": "## Table of Contents"}, {"metadata": {}, "cell_type": "markdown", "source": "1. [Getting Setup](#setup1)<br>\n \n2. [Data Exploration](#explore)<br>\n \n3. [Create Testing, Training and Validation Groups](#groups)<br>\n\n4. [Conclusions](#conc)<br>"}, {"metadata": {}, "cell_type": "markdown", "source": "## 1.0 Getting Set-Up <a id=\"setup1\"></a>"}, {"metadata": {}, "cell_type": "markdown", "source": "Import all of the relevant Python Libraries"}, {"metadata": {"scrolled": true}, "cell_type": "code", "source": "import numpy as np\nimport numpy.dual as dual\n\nimport pandas as pd\n", "execution_count": 1, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "Import the data from GitHub"}, {"metadata": {}, "cell_type": "code", "source": "#Remove the data if you run this notebook more than once\n!rm equipment_failure_data_1.csv", "execution_count": 2, "outputs": [{"output_type": "stream", "text": "rm: cannot remove 'equipment_failure_data_1.csv': No such file or directory\r\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "code", "source": "#import first half from github\n!wget https://raw.githubusercontent.com/shadgriffin/panelsampling/main/equipment_failure_data_1.csv", "execution_count": 3, "outputs": [{"output_type": "stream", "text": "--2021-04-01 16:31:04--  https://raw.githubusercontent.com/shadgriffin/panelsampling/main/equipment_failure_data_1.csv\nResolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.108.133, 185.199.110.133, ...\nConnecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 11219474 (11M) [text/plain]\nSaving to: \u2018equipment_failure_data_1.csv\u2019\n\nequipment_failure_d 100%[===================>]  10.70M  --.-KB/s    in 0.09s   \n\n2021-04-01 16:31:04 (122 MB/s) - \u2018equipment_failure_data_1.csv\u2019 saved [11219474/11219474]\n\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "code", "source": "# Convert csv to pandas dataframe\npd_data_1 = pd.read_csv(\"equipment_failure_data_1.csv\", sep=\",\", header=0)", "execution_count": 5, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "#Remove the data if you run this notebook more than once\n!rm equipment_failure_data_2.csv", "execution_count": 6, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "#Import the second half from github\n!wget https://raw.githubusercontent.com/shadgriffin/panelsampling/main/equipment_failure_data_2.csv", "execution_count": 7, "outputs": [{"output_type": "stream", "text": "--2021-04-01 16:31:24--  https://raw.githubusercontent.com/shadgriffin/panelsampling/main/equipment_failure_data_2.csv\nResolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.108.133, 185.199.109.133, ...\nConnecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 11762512 (11M) [text/plain]\nSaving to: \u2018equipment_failure_data_2.csv\u2019\n\nequipment_failure_d 100%[===================>]  11.22M  --.-KB/s    in 0.09s   \n\n2021-04-01 16:31:24 (120 MB/s) - \u2018equipment_failure_data_2.csv\u2019 saved [11762512/11762512]\n\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "code", "source": "# convert to pandas dataframe\npd_data_2 = pd.read_csv(\"equipment_failure_data_2.csv\", sep=\",\", header=0)", "execution_count": 8, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "#concatenate the two data files into one dataframe\npd_data=pd.concat([pd_data_1, pd_data_2])\n\n", "execution_count": 9, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "## 2.0 Data Exporation <a id=\"explore\"></a>"}, {"metadata": {}, "cell_type": "code", "source": "pd_data.head()", "execution_count": 10, "outputs": [{"output_type": "execute_result", "execution_count": 10, "data": {"text/plain": "       ID     DATE REGION_CLUSTER MAINTENANCE_VENDOR MANUFACTURER  WELL_GROUP  \\\n0  100001  12/2/14              G                  O            Y           1   \n1  100001  12/3/14              G                  O            Y           1   \n2  100001  12/4/14              G                  O            Y           1   \n3  100001  12/5/14              G                  O            Y           1   \n4  100001  12/6/14              G                  O            Y           1   \n\n         S15         S17    S13      S5       S16  S19        S18  \\\n0  11.088000  145.223448  39.34  3501.0  8.426869  1.9  24.610345   \n1   8.877943  187.573214  39.20  3489.0  6.483714  1.9  24.671429   \n2   8.676444  148.363704  38.87  3459.0  6.159659  2.0  24.733333   \n3   9.988338  133.660000  39.47  3513.0  9.320308  2.0  24.773077   \n4   8.475264  197.181600  40.33  3589.0  8.022960  1.5  24.808000   \n\n   EQUIPMENT_FAILURE   S8  AGE_OF_EQUIPMENT  \n0                  0  0.0               880  \n1                  0  0.0               881  \n2                  0  0.0               882  \n3                  0  0.0               883  \n4                  0  0.0               884  ", "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ID</th>\n      <th>DATE</th>\n      <th>REGION_CLUSTER</th>\n      <th>MAINTENANCE_VENDOR</th>\n      <th>MANUFACTURER</th>\n      <th>WELL_GROUP</th>\n      <th>S15</th>\n      <th>S17</th>\n      <th>S13</th>\n      <th>S5</th>\n      <th>S16</th>\n      <th>S19</th>\n      <th>S18</th>\n      <th>EQUIPMENT_FAILURE</th>\n      <th>S8</th>\n      <th>AGE_OF_EQUIPMENT</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>100001</td>\n      <td>12/2/14</td>\n      <td>G</td>\n      <td>O</td>\n      <td>Y</td>\n      <td>1</td>\n      <td>11.088000</td>\n      <td>145.223448</td>\n      <td>39.34</td>\n      <td>3501.0</td>\n      <td>8.426869</td>\n      <td>1.9</td>\n      <td>24.610345</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>880</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>100001</td>\n      <td>12/3/14</td>\n      <td>G</td>\n      <td>O</td>\n      <td>Y</td>\n      <td>1</td>\n      <td>8.877943</td>\n      <td>187.573214</td>\n      <td>39.20</td>\n      <td>3489.0</td>\n      <td>6.483714</td>\n      <td>1.9</td>\n      <td>24.671429</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>881</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>100001</td>\n      <td>12/4/14</td>\n      <td>G</td>\n      <td>O</td>\n      <td>Y</td>\n      <td>1</td>\n      <td>8.676444</td>\n      <td>148.363704</td>\n      <td>38.87</td>\n      <td>3459.0</td>\n      <td>6.159659</td>\n      <td>2.0</td>\n      <td>24.733333</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>882</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>100001</td>\n      <td>12/5/14</td>\n      <td>G</td>\n      <td>O</td>\n      <td>Y</td>\n      <td>1</td>\n      <td>9.988338</td>\n      <td>133.660000</td>\n      <td>39.47</td>\n      <td>3513.0</td>\n      <td>9.320308</td>\n      <td>2.0</td>\n      <td>24.773077</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>883</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>100001</td>\n      <td>12/6/14</td>\n      <td>G</td>\n      <td>O</td>\n      <td>Y</td>\n      <td>1</td>\n      <td>8.475264</td>\n      <td>197.181600</td>\n      <td>40.33</td>\n      <td>3589.0</td>\n      <td>8.022960</td>\n      <td>1.5</td>\n      <td>24.808000</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>884</td>\n    </tr>\n  </tbody>\n</table>\n</div>"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "markdown", "source": "ID -- ID field that represents a specific machine.\n\nDATE -- The date of the observation.\n\nREGION_CLUSTER -- a field that represents the region in which the machine is located.\n\nMAINTENANCE_VENDOR -- a field that represents the company that provides maintenance and service to the machine.\n\nMANUFACTURER -- the company that manufactured the equipment in question.\n\nWELL_GROUP -- a field representing the type of Machine.\n\n\nEQUIPMENT_AGE -- Age of the machine, in days.\n\nS15 -- A Sensor Value.\n\nS17 -- A Sensor Value.\n\nS13 -- A Sensor Value.\n\nS16 -- A Sensor Value.\n\nS19 -- A Sensor Value.\n\nS18 -- A Sensor Value.\n\nS8  -- A Sensor Value.\n\nEQUIPMENT_FAILURE -- A '1' means that the equipment failed.  A '0' means the equipment did not fail.\n\n\n\n\n\n\n"}, {"metadata": {}, "cell_type": "markdown", "source": "\nAs you can see, this data represents a panel data set.  We have multiple machines measured over mulitple time periods.  ID represents the machine and DATE represents the date.  Now, let's examine how many machines and how many dates we have."}, {"metadata": {}, "cell_type": "markdown", "source": "Examine the number of rows and columns.  The data has 307,751 rows and 16 columns"}, {"metadata": {"scrolled": true}, "cell_type": "code", "source": "\npd_data.shape", "execution_count": 11, "outputs": [{"output_type": "execute_result", "execution_count": 11, "data": {"text/plain": "(307751, 16)"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "markdown", "source": "There are 421 machines in the data set"}, {"metadata": {}, "cell_type": "code", "source": "\nxxxx = pd.DataFrame(pd_data.groupby(['ID']).agg(['count']))\nxxxx.shape", "execution_count": 12, "outputs": [{"output_type": "execute_result", "execution_count": 12, "data": {"text/plain": "(421, 15)"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "markdown", "source": "there are 731 unique dates in the data set"}, {"metadata": {}, "cell_type": "code", "source": "\nxxxx = pd.DataFrame(pd_data.groupby(['DATE']).agg(['count']))\nxxxx.shape", "execution_count": 13, "outputs": [{"output_type": "execute_result", "execution_count": 13, "data": {"text/plain": "(731, 15)"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "markdown", "source": "\nWe have 731 unique dates. \n\n\nSo if we have 421 machines and 731 unique dates.\n\n"}, {"metadata": {}, "cell_type": "markdown", "source": "### 3.0 Create the Testing, Training and Validation Groupings by Entity (machine id) <a id=\"groups\"></a>"}, {"metadata": {}, "cell_type": "markdown", "source": "We could just randomly assign each record to one of the three groups.  While that could work, I wouldn't recommend it.  I would recommend assigning the group at an entity level (machine in this case).  \n\nWhy?  \n\nWell, I could use some multi-syllabic words (like auto-correlation or mayonnaise) to describe why, but let's just think about it.\n\nWhy do we separate the data into training, testing and validation groups? \n\nWe want to ensure that our model is not over-fit.  In other words, we want to make sure that our model applies to new data as it comes available. \n\nFor example, let's pretend that we built a model that predicts what happened last year with 100% accuracy. Good job, right?  Well, it really doesn't matter how well the model predicts last year.  We need it to predict today, tomorrow and the day after that.  So, if a model predicts last year with 100% accuracy but fails to predict tomorrow, it kind of sucks.\n\nBuilding a model on the training data and verifying the accuracy on the testing and validation data set keeps this from happening.\n\n\n\n\n\n"}, {"metadata": {}, "cell_type": "markdown", "source": "In order to prevent over-fitting we need our training, testing and validation groups to be independent.  That is, we need to ensure that the data in the training group is different from the testing and validation groups.  Or, at least as different as possible.\n\nSo what happens if we just randomly assign each record to each of the groups in question?  We end up with records from each entity in each group.  For example with a simple random selection method, if we are dealing with machines, it is probable that machine 123 will appear in your training, testing and validation groups.  If you are dealing with individuals, it is probable that Steve Wakahookie will appear in all three groups.  \n\nIn other words, your training, testing and validation groups ARE NOT as independent because good ol' Steve and machine 123 are present in all three groups.  \n\nNow, if you assign group membership based on entity, all of the Steve's records will be in either the training, testing or validation group.  Likewise, all of the records associated with machine 123 will be in only one of the three groups."}, {"metadata": {}, "cell_type": "markdown", "source": "Get a Unique List of All IDs "}, {"metadata": {"scrolled": true}, "cell_type": "code", "source": "aa=pd_data\n\npd_id=aa.drop_duplicates(subset='ID')\npd_id=pd_id[['ID']]\npd_id.shape\n", "execution_count": 14, "outputs": [{"output_type": "execute_result", "execution_count": 14, "data": {"text/plain": "(421, 1)"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "markdown", "source": "Create a new variable with a random number between 0 and 1"}, {"metadata": {}, "cell_type": "code", "source": "np.random.seed(42)\npd_id['wookie'] = (np.random.randint(0, 10000, pd_id.shape[0]))/10000", "execution_count": 15, "outputs": []}, {"metadata": {"scrolled": true}, "cell_type": "code", "source": "\npd_id=pd_id[['ID', 'wookie']]", "execution_count": 16, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "Give each record a 30% chance of being in the validation, a 35% chance of being in the testing and a 35% chance of being in the training data set\n"}, {"metadata": {"scrolled": true}, "cell_type": "code", "source": "pd_id['MODELING_GROUP'] = np.where(((pd_id.wookie <= 0.35)), 'TRAINING', np.where(((pd_id.wookie <= 0.65)), 'VALIDATION', 'TESTING'))", "execution_count": 17, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "This is how many machines fall in each group"}, {"metadata": {"scrolled": true}, "cell_type": "code", "source": "tips_summed = pd_id.groupby(['MODELING_GROUP'])['wookie'].count()\ntips_summed", "execution_count": 18, "outputs": [{"output_type": "execute_result", "execution_count": 18, "data": {"text/plain": "MODELING_GROUP\nTESTING       149\nTRAINING      146\nVALIDATION    126\nName: wookie, dtype: int64"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "markdown", "source": "Append the Group of each id to each individual record"}, {"metadata": {"scrolled": true}, "cell_type": "code", "source": "pd_data=pd_data.sort_values(by=['ID'], ascending=[True])\npd_id=pd_id.sort_values(by=['ID'], ascending=[True])", "execution_count": 19, "outputs": []}, {"metadata": {"scrolled": true}, "cell_type": "code", "source": "pd_data =pd_data.merge(pd_id, on=['ID'], how='inner')\n\npd_data.head()", "execution_count": 20, "outputs": [{"output_type": "execute_result", "execution_count": 20, "data": {"text/plain": "       ID     DATE REGION_CLUSTER MAINTENANCE_VENDOR MANUFACTURER  WELL_GROUP  \\\n0  100001  12/2/14              G                  O            Y           1   \n1  100001  3/29/16              G                  O            Y           1   \n2  100001  3/30/16              G                  O            Y           1   \n3  100001  3/31/16              G                  O            Y           1   \n4  100001   4/1/16              G                  O            Y           1   \n\n      S15         S17    S13      S5        S16  S19        S18  \\\n0  11.088  145.223448  39.34  3501.0   8.426869  1.9  24.610345   \n1  18.960    0.000000  38.87  3459.0  10.047300  1.3  36.600000   \n2  29.040    0.000000  37.36  3325.0  10.235100  1.4  36.000000   \n3  18.000    0.000000  38.81  3454.0   8.544900  1.4  36.100000   \n4  26.160    0.000000  39.47  3513.0  10.986300  1.4  36.300000   \n\n   EQUIPMENT_FAILURE     S8  AGE_OF_EQUIPMENT  wookie MODELING_GROUP  \n0                  0   0.00               880   0.727        TESTING  \n1                  0  34.37              1363   0.727        TESTING  \n2                  0  32.37              1364   0.727        TESTING  \n3                  0  34.44              1365   0.727        TESTING  \n4                  0  33.26              1366   0.727        TESTING  ", "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ID</th>\n      <th>DATE</th>\n      <th>REGION_CLUSTER</th>\n      <th>MAINTENANCE_VENDOR</th>\n      <th>MANUFACTURER</th>\n      <th>WELL_GROUP</th>\n      <th>S15</th>\n      <th>S17</th>\n      <th>S13</th>\n      <th>S5</th>\n      <th>S16</th>\n      <th>S19</th>\n      <th>S18</th>\n      <th>EQUIPMENT_FAILURE</th>\n      <th>S8</th>\n      <th>AGE_OF_EQUIPMENT</th>\n      <th>wookie</th>\n      <th>MODELING_GROUP</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>100001</td>\n      <td>12/2/14</td>\n      <td>G</td>\n      <td>O</td>\n      <td>Y</td>\n      <td>1</td>\n      <td>11.088</td>\n      <td>145.223448</td>\n      <td>39.34</td>\n      <td>3501.0</td>\n      <td>8.426869</td>\n      <td>1.9</td>\n      <td>24.610345</td>\n      <td>0</td>\n      <td>0.00</td>\n      <td>880</td>\n      <td>0.727</td>\n      <td>TESTING</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>100001</td>\n      <td>3/29/16</td>\n      <td>G</td>\n      <td>O</td>\n      <td>Y</td>\n      <td>1</td>\n      <td>18.960</td>\n      <td>0.000000</td>\n      <td>38.87</td>\n      <td>3459.0</td>\n      <td>10.047300</td>\n      <td>1.3</td>\n      <td>36.600000</td>\n      <td>0</td>\n      <td>34.37</td>\n      <td>1363</td>\n      <td>0.727</td>\n      <td>TESTING</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>100001</td>\n      <td>3/30/16</td>\n      <td>G</td>\n      <td>O</td>\n      <td>Y</td>\n      <td>1</td>\n      <td>29.040</td>\n      <td>0.000000</td>\n      <td>37.36</td>\n      <td>3325.0</td>\n      <td>10.235100</td>\n      <td>1.4</td>\n      <td>36.000000</td>\n      <td>0</td>\n      <td>32.37</td>\n      <td>1364</td>\n      <td>0.727</td>\n      <td>TESTING</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>100001</td>\n      <td>3/31/16</td>\n      <td>G</td>\n      <td>O</td>\n      <td>Y</td>\n      <td>1</td>\n      <td>18.000</td>\n      <td>0.000000</td>\n      <td>38.81</td>\n      <td>3454.0</td>\n      <td>8.544900</td>\n      <td>1.4</td>\n      <td>36.100000</td>\n      <td>0</td>\n      <td>34.44</td>\n      <td>1365</td>\n      <td>0.727</td>\n      <td>TESTING</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>100001</td>\n      <td>4/1/16</td>\n      <td>G</td>\n      <td>O</td>\n      <td>Y</td>\n      <td>1</td>\n      <td>26.160</td>\n      <td>0.000000</td>\n      <td>39.47</td>\n      <td>3513.0</td>\n      <td>10.986300</td>\n      <td>1.4</td>\n      <td>36.300000</td>\n      <td>0</td>\n      <td>33.26</td>\n      <td>1366</td>\n      <td>0.727</td>\n      <td>TESTING</td>\n    </tr>\n  </tbody>\n</table>\n</div>"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "markdown", "source": "This is how many records are in each group."}, {"metadata": {"scrolled": true}, "cell_type": "code", "source": "tips_summed = pd_data.groupby(['MODELING_GROUP'])['wookie'].count()\ntips_summed", "execution_count": 21, "outputs": [{"output_type": "execute_result", "execution_count": 21, "data": {"text/plain": "MODELING_GROUP\nTESTING       108919\nTRAINING      106726\nVALIDATION     92106\nName: wookie, dtype: int64"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "markdown", "source": "##  4.0 Conclusions <a id=\"conc\"></a>"}, {"metadata": {}, "cell_type": "markdown", "source": "So, there you go.  Now, we are ready to build a machine learning model.  By using the placing entities and not records into your training, testing and validation groups you can ensure independence between the groups and build models that work yesterday, today and tomorrow.\n\n\n"}, {"metadata": {}, "cell_type": "markdown", "source": "### Author\n\n\n"}, {"metadata": {}, "cell_type": "markdown", "source": "\n**Shad Griffin** is a Certified Thought Leader and a Data Scientist at IBM"}, {"metadata": {}, "cell_type": "markdown", "source": "<hr>\nCopyright &copy;  This notebook and its source code are released under the terms of the MIT License.\n\n"}, {"metadata": {}, "cell_type": "code", "source": "", "execution_count": null, "outputs": []}], "metadata": {"kernelspec": {"name": "python3", "display_name": "Python 3.7", "language": "python"}, "language_info": {"name": "python", "version": "3.7.10", "mimetype": "text/x-python", "codemirror_mode": {"name": "ipython", "version": 3}, "pygments_lexer": "ipython3", "nbconvert_exporter": "python", "file_extension": ".py"}}, "nbformat": 4, "nbformat_minor": 1}